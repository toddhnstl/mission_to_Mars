{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scrape everything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dictionary will hold everything we pull from all the sites\n",
    "scraped_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site 1 - \"https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\"\n",
    "news_url = \"https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\" # probably need to replace this since it redirects\n",
    "news_response = requests.get(news_url)\n",
    "\n",
    "\n",
    "# use beautiful soup to parse the url above\n",
    "news_soup = bs(news_response.text, 'html.parser')\n",
    "#newPSoup = bs(news_response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Paragraph=====\n",
      "None\n",
      "=========\n",
      "\n",
      "\n",
      "=========\n",
      "<div class=\"content_title\">\n",
      "<a href=\"/news/8508/nasa-invites-students-to-name-mars-2020-rover/\">\n",
      "NASA Invites Students to Name Mars 2020 Rover\n",
      "</a>\n",
      "</div>\n",
      "\n",
      "NASA Invites Students to Name Mars 2020 Rover\n",
      "=========\n",
      "\n",
      "\n",
      "====Paragraph=====\n",
      "None\n",
      "=========\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # example_title_div = '<div class=\"content_title\"><a href=\"/news/8520/nasas-mars-2020-rover-tests-descent-stage-separation/\" target=\"_self\">NASAs Mars 2020 Rover Tests Descent-Stage Separation</a></div>'\n",
    "# # example_paragraph_div = '<div class=\"article_teaser_body\">A crane lifts the rocket-powered descent stage away from NASAs Mars 2020 rover after technicians tested the pyrotechnic charges that separate the two spacecraft.</div>'\n",
    "\n",
    "\n",
    "# # use bs to find() the example_title_div and filter on the class_='content_tile'\n",
    "\n",
    "\n",
    "# # presults = newPSoup.find_all('li', class_='slide')\n",
    "# # print(presults)\n",
    "\n",
    "# results = news_soup.find('div', class_='content_title')\n",
    "# print(\"==== News Title =====\")\n",
    "# print(results)\n",
    "# print(\"\")\n",
    "# news_title = results.a.text\n",
    "# news_title = news_title.replace('\\n', '')\n",
    "# print(news_title)\n",
    "# scraped_data['news_title'] = news_title #- load the dataframe with Key/value pair\n",
    "# print(\"=========\")\n",
    "# print(\"\")\n",
    "# print(\"\")\n",
    "\n",
    "# # use bs to find() the example_title_div and filter on the class_='article_teaser_body'\n",
    "# presults = news_soup.find('div', class_='article_teaser_body')\n",
    "# print(\"====Paragraph=====\")\n",
    "# print(presults)\n",
    "# print(\"=========\")\n",
    "# print(\"\")\n",
    "# print(\"\")\n",
    "\n",
    "# # # news_p = \"FILL IN THE PARAGRAPH\"\n",
    "# # # scraped_data['news_p'] = news_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I'm getting nowhere with just BS.  Try site 1 with splinter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "browser.visit(news_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"New evidence suggests salty, shallow ponds once dotted a Martian crater â€” a sign of the planet's drying climate.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = browser.html\n",
    "soup = bs(html, 'html.parser')\n",
    "\n",
    "\n",
    "# Get an article block.\n",
    "art_teaser_body = soup.find('li', class_='slide')\n",
    "\n",
    "# Parse out the title\n",
    "title = art_teaser_body.find('div',  class_='content_title')\n",
    "news_title = title.text\n",
    "\n",
    "# Parse out the body text\n",
    "news_p = art_teaser_body.find('div',  class_='article_teaser_body').text\n",
    "news_p\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data['news_title'] = news_title\n",
    "scraped_data['news_p'] = news_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site 2 - https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\n",
    "\n",
    "# use splinter to connect to the url and navigate, then use bs4 to repeat what you did in site 1\n",
    "\n",
    "# Example:\n",
    "featured_image_url = 'https://www.jpl.nasa.gov/spaceimages/images/largesize/PIA16225_hires.jpg'\n",
    "scraped_data['featured_image_url'] = featured_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site 3 - https://twitter.com/marswxreport?lang=en\n",
    "\n",
    "# grab the latest tweet and be careful its a weather tweet\n",
    "\n",
    "# Example:\n",
    "mars_weather = 'Sol 1801 (Aug 30, 2017), Sunny, high -21C/-5F, low -80C/-112F, pressure at 8.82 hPa, daylight 06:09-17:55'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site 4 - \n",
    "facts_url = 'https://space-facts.com/mars/'\n",
    "\n",
    "# use pandas to parse the table\n",
    "\n",
    "facts_df = pd.read_html(facts_url)[0]\n",
    "\n",
    "# convert facts_df to a html string and add to dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site 5 \n",
    "\n",
    "# use bs4 to scrape the title and url and add to dictionary\n",
    "\n",
    "# Example:\n",
    "hemisphere_image_urls = [\n",
    "    {\"title\": \"Valles Marineris Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Cerberus Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Schiaparelli Hemisphere\", \"img_url\": \"...\"},\n",
    "    {\"title\": \"Syrtis Major Hemisphere\", \"img_url\": \"...\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File-> download as python into a new module called scrape_mars.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use day 3 09-Ins_Scrape_And_Render/app.py as a blue print on how to finish the homework.\n",
    "\n",
    "# replace the contents of def index() and def scraper() appropriately.\n",
    "\n",
    "# change the index.html to render the site with all the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pandas] *",
   "language": "python",
   "name": "conda-env-pandas-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
